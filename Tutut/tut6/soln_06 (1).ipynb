{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import inv\n",
        "from sklearn.preprocessing import PolynomialFeatures"
      ],
      "metadata": {
        "id": "5G72QEfAoTf8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3:\n",
        "(d) Given ð²=[0 1]^T, can a unique solution be obtained in dual form? If so, proceed to solve it.\n"
      ],
      "metadata": {
        "id": "nRM-9M7lngyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[1,0,1], [1,-1,1]])\n",
        "y = np.array([0, 1])\n",
        "print(y)\n",
        "## Generate polynomial features\n",
        "order = 3\n",
        "poly = PolynomialFeatures(order)\n",
        "P = poly.fit_transform(X)\n",
        "## dual solution (without ridge)\n",
        "w_dual = P.T @ inv(P @ P.T) @ y.T\n",
        "print(w_dual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk_3zcKQniQQ",
        "outputId": "7295a311-bb6f-486e-9367-197734bde59f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n",
            "[ 0.   0.  -0.1  0.   0.  -0.1  0.   0.1 -0.1  0.   0.  -0.1  0.   0.1\n",
            " -0.1  0.  -0.1  0.1 -0.1  0. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(d) Given ð²=[0 1]^T, can the primal ridge regression be applied to obtain a unique solution? If so, proceed to solve it."
      ],
      "metadata": {
        "id": "EZGklqFnn1tT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## primal ridge\n",
        "reg_L = 0.0001*np.identity(P.shape[1])\n",
        "w_primal_ridge = inv(P.T @ P + reg_L) @ P.T @ y.T\n",
        "print(w_primal_ridge)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJn53EGKn0Sg",
        "outputId": "0866982f-55b7-4598-fa51-18742ae121f2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 9.99963731e-07  9.99966232e-07 -9.99980001e-02  9.99970894e-07\n",
            "  9.99969188e-07 -9.99980001e-02  9.99968734e-07  9.99980000e-02\n",
            " -9.99980001e-02  9.99973167e-07  9.99969302e-07 -9.99980000e-02\n",
            "  9.99968165e-07  9.99980001e-02 -9.99980000e-02  9.99969075e-07\n",
            " -9.99980001e-02  9.99980000e-02 -9.99980000e-02  9.99967597e-07]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: Predict the class label for {ð‘¥ = âˆ’0.1} and {ð‘¥ = 0.4} using linear regression with signum discrimination."
      ],
      "metadata": {
        "id": "Mc7jux_6o5Qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[1,-1], [1,0], [1,0.5], [1,0.3], [1,0.8]])\n",
        "y = np.array([1, 1, -1, 1, -1])\n",
        "## Linear regression for classification\n",
        "w = inv(X.T @ X) @ X.T @ y\n",
        "print(w)\n",
        "Xt = np.array([[1,-0.1], [1,0.4]])\n",
        "y_predict = Xt @ w\n",
        "print(y_predict)\n",
        "y_class_predict = np.sign(y_predict)\n",
        "print(y_class_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfGB6PDMo5rT",
        "outputId": "22586921-fa9f-4c6e-870b-b618a4666388"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.33333333 -1.11111111]\n",
            "[ 0.44444444 -0.11111111]\n",
            "[ 1. -1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: (a) Predict the class label for {ð‘¥ = âˆ’0.1} and {ð‘¥ = 0.4} based on linear regression towards a one-hot encoded target"
      ],
      "metadata": {
        "id": "zoX21ckWpM5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[1,-1], [1,0], [1,0.5], [1,0.3], [1,0.8]])\n",
        "Y = np.array([[1,0,0], [1,0,0], [0,1,0], [0,0,1], [0,1,0]])\n",
        "## Linear regression for classification\n",
        "W = inv(X.T @ X) @ X.T @ Y\n",
        "print(W)\n",
        "Xt = np.array([[1,-0.1], [1,0.4]])\n",
        "y_predict = Xt @ W\n",
        "print(y_predict)\n",
        "y_class_predict = [[1 if y == max(x) else 0 for y in x] for x in y_predict]\n",
        "print(y_class_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldKJ02LbpdEO",
        "outputId": "bcf9fb66-98fa-4dea-e5aa-a37fbae46aee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.47798742  0.33333333  0.18867925]\n",
            " [-0.64989518  0.55555556  0.09433962]]\n",
            "[[0.54297694 0.27777778 0.17924528]\n",
            " [0.21802935 0.55555556 0.22641509]]\n",
            "[[1, 0, 0], [0, 1, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) Predict the class label for {ð‘¥ = âˆ’0.1} and {ð‘¥ = 0.4} using a polynomial model of 5 order and a one-hot encoded target."
      ],
      "metadata": {
        "id": "JGmH-EYDphPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Polynomial regression for classification\n",
        "## Generate polynomial features\n",
        "order = 5\n",
        "poly = PolynomialFeatures(order)\n",
        "## only the data column (2nd) is needed for generation of polynomial terms\n",
        "reshaped = X[:,1].reshape(len(X[:,1]),1)\n",
        "P = poly.fit_transform(reshaped)\n",
        "reshaped = Xt[:,1].reshape(len(Xt[:,1]),1)\n",
        "Pt = poly.fit_transform(reshaped)\n",
        "## dual solution (without ridge)\n",
        "Wp_dual = P.T @ inv(P @ P.T) @ Y\n",
        "print(Wp_dual)\n",
        "yp_predict = Pt @ Wp_dual\n",
        "print(yp_predict)\n",
        "yp_class_predict = [[1 if y == max(x) else 0 for y in x] for x in yp_predict ]\n",
        "print(yp_class_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX3bg4wBpf1W",
        "outputId": "96a04c0b-ecec-405c-8b61-3fecbd4c035b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.00000000e+00  1.77635684e-13 -3.41060513e-13]\n",
            " [-5.30313768e+00 -3.70234958e+00  9.00548727e+00]\n",
            " [ 5.21976232e+00  1.08728407e+01 -1.60926030e+01]\n",
            " [ 6.66624941e+00  9.46978846e+00 -1.61360379e+01]\n",
            " [-6.47651463e+00 -1.29098961e+01  1.93864107e+01]\n",
            " [-2.61986403e+00 -7.80449422e+00  1.04243583e+01]]\n",
            "[[ 1.57522369  0.46828063 -1.04350432]\n",
            " [-0.05207932  0.45436978  0.59770954]]\n",
            "[[1, 0, 0], [0, 0, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: (continued from Q3 of Tutorial 2):\n",
        "Get the data set â€œfrom sklearn.datasets import load_irisâ€. Use Python to perform the following tasks.\n",
        "\n",
        "(a) Split the database into two sets: 74% of samples for training, and 26% of samples for testing. Hint: you might want to utilize from sklearn.model_selection import train_test_split for the splitting."
      ],
      "metadata": {
        "id": "7prM7s0AqiCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## (a) split data\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris_dataset = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "iris_dataset['data'], iris_dataset['target'], test_size=0.26, random_state=0)"
      ],
      "metadata": {
        "id": "Sn_hrS0UqlWn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJpPdGTrcaTC",
        "outputId": "14e7c1e6-ffd2-48a1-e589-2ace651ca683"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 0, 2, 0, 0, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1,\n",
              "       0, 2, 1, 1, 1, 1, 2, 0, 0, 2, 1, 0, 0, 1, 0, 2, 1, 0, 1, 2, 1, 0,\n",
              "       2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 1, 2, 2,\n",
              "       0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 1, 2, 1, 0, 2, 0, 2, 0, 0, 2, 0, 2,\n",
              "       1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0, 0, 2, 1, 2,\n",
              "       0])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) Construct the target output using one-hot encoding."
      ],
      "metadata": {
        "id": "vz_FY2bqqyE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (b) one-hot encoding\n",
        "Ytr_onehot = list()\n",
        "for i in y_train:\n",
        "  letter = [0, 0, 0]\n",
        "  letter[i] = 1\n",
        "  Ytr_onehot.append(letter)\n",
        "Yts_onehot = list()\n",
        "for i in y_test:\n",
        "  letter = [0, 0, 0]\n",
        "  letter[i] = 1\n",
        "  Yts_onehot.append(letter)\n",
        "\n",
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# onehot_encoder=OneHotEncoder(sparse=False)\n",
        "# reshaped = y_train.reshape(len(y_train), 1)\n",
        "# tr_onehot = onehot_encoder.fit_transform(reshaped)\n",
        "# reshaped = y_test.reshape(len(y_test), 1)\n",
        "# Yts_onehot = onehot_encoder.fit_transform(reshaped)"
      ],
      "metadata": {
        "id": "wEpHDTaRqzs_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWA6AKMaeAHE",
        "outputId": "05144ca5-4b13-474d-ded8-4792ba5d9299"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.1],\n",
              "       [ 0.4]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Perform a linear regression for classification (without inclusion of ridge, utilizing one-hot encoding for the\n",
        "learning target) and compute the number of test samples that are classified correctly."
      ],
      "metadata": {
        "id": "0g-_d3gFrJV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## (c) Linear Classification\n",
        "w = inv(X_train.T @ X_train) @ X_train.T @ Ytr_onehot\n",
        "print(w)\n",
        "# calculate the output based on the estimated w and test input X and then assign to one of the classes based on one hot encoding\n",
        "yt_est = X_test.dot(w)\n",
        "yt_cls = [[1 if y == max(x) else 0 for y in x] for x in yt_est ]\n",
        "print(yt_cls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOT_cJyyrLsQ",
        "outputId": "e300b193-2c6b-4a32-e036-f13abf362352"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.11529555  0.20404125 -0.15416052]\n",
            " [ 0.21791487 -0.29396894  0.14549901]\n",
            " [-0.25363127  0.18246449  0.0362187 ]\n",
            " [-0.04023153 -0.58240246  0.57367321]]\n",
            "[[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 0, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare the predicted y with the ground truth\n",
        "m1 = np.matrix(Yts_onehot)\n",
        "m2 = np.matrix(yt_cls)\n",
        "difference = np.abs(m1 - m2)\n",
        "print(difference)\n",
        "# calculate the error rate/accuracy\n",
        "correct = np.where(~difference.any(axis=1))[0]\n",
        "print(correct)\n",
        "# print(~difference.any(axis=1))\n",
        "# print(np.asarray(~difference.any(axis=1)).nonzero())\n",
        "accuracy = len(correct)/len(difference)\n",
        "print(len(correct))\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3esDSg7QecSE",
        "outputId": "d97f0a1d-5c4b-4ccb-8195-e58035f1c41c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 1 1]]\n",
            "[ 0  1  2  4  5  6  8  9 12 13 15 17 18 19 20 22 23 24 25 26 27 28 29 30\n",
            " 32 33 34 36]\n",
            "28\n",
            "0.717948717948718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(d) Using the same training and test sets as in above, perform a 2nd order polynomial regression for classification (again, without inclusion of ridge, utilizing one-hot encoding for the learning target) and compute the number of test samples that are classified correctly. Hint: you might want to use from sklearn.preprocessing import PolynomialFeatures for generation of the polynomial\n",
        "matrix."
      ],
      "metadata": {
        "id": "k-ab6TkqrOtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## (d) Polynomial Classification\n",
        "poly = PolynomialFeatures(2)\n",
        "P = poly.fit_transform(X_train)\n",
        "Pt = poly.fit_transform(X_test)\n",
        "if P.shape[0] > P.shape[1]:\n",
        "  wp = inv(P.T @ P) @ P.T @ Ytr_onehot\n",
        "else:\n",
        "  wp = P.T @ inv(P @ P.T) @ Ytr_onehot\n",
        "print(wp)\n",
        "yt_est_p = Pt.dot(wp)\n",
        "yt_cls_p = [[1 if y == max(x) else 0 for y in x] for x in yt_est_p ]\n",
        "print(yt_cls_p)\n",
        "m1 = np.matrix(Yts_onehot)\n",
        "m2 = np.matrix(yt_cls_p)\n",
        "difference = np.abs(m1 - m2)\n",
        "print(difference)\n",
        "correct_p = np.where(~difference.any(axis=1))[0]\n",
        "accuracy_p = len(correct_p)/len(difference)\n",
        "print(len(correct_p))\n",
        "print(accuracy_p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfsra4XVrTMi",
        "outputId": "df0edf9c-bb7e-43f2-af18-b5655d1b1f3d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.76299101  1.13822047  0.62477054]\n",
            " [ 0.6014925  -0.88680328  0.28531078]\n",
            " [ 0.59784609 -0.10575032 -0.49209577]\n",
            " [-0.85299054  2.07290305 -1.2199125 ]\n",
            " [ 0.14176955 -3.06489748  2.92312792]\n",
            " [-0.01193797  0.23828328 -0.22634531]\n",
            " [-0.12685437 -0.44906348  0.57591784]\n",
            " [-0.0345378  -0.02301658  0.05755437]\n",
            " [ 0.0405222  -0.19925454  0.15873235]\n",
            " [ 0.00558587  0.31463436 -0.32022024]\n",
            " [ 0.09555557 -0.10296338  0.00740781]\n",
            " [-0.14809056  1.04541241 -0.89732185]\n",
            " [ 0.0906437  -0.37729444  0.28665074]\n",
            " [-0.07777166  1.0010156  -0.92324394]\n",
            " [ 0.12824961 -1.27034815  1.14209854]]\n",
            "[[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0]]\n",
            "[[0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 1 1]\n",
            " [0 0 0]]\n",
            "38\n",
            "0.9743589743589743\n"
          ]
        }
      ]
    }
  ]
}